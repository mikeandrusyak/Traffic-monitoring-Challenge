{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from utils.plots import visualize_vehicle_trajectories\n",
    "from utils.loader import load_data_from_database\n",
    "from utils.transformer import categorize_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ed736",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Do you want to load data from the database? This may take a while.\")\n",
    "if input(\"Type 'y' to proceed: \").lower() == 'y':\n",
    "    df = load_data_from_database()\n",
    "    df = df.sort_values(['date_time', 'frame_id'])\n",
    "else:\n",
    "    df = pd.read_csv(\"raw_traffic_data.csv\", parse_dates=['date_time'])\n",
    "    df = df.sort_values(['date_time', 'frame_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed88dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['session_id'] = (\n",
    "    (df['frame_id'].diff() < 0)\n",
    ").cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('session_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select one stable session and sort\n",
    "session_id_to_analyze = 0\n",
    "session_df = df[df['session_id'] == session_id_to_analyze].sort_values(['vehicle_id', 'date_time'])\n",
    "\n",
    "# Filter vehicle_id with less than 20 records\n",
    "vehicle_counts = session_df['vehicle_id'].value_counts()\n",
    "valid_vehicles = vehicle_counts[vehicle_counts >= 20].index\n",
    "session_df = session_df[session_df['vehicle_id'].isin(valid_vehicles)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d48de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def classify_tracks(metrics):\n",
    "    \"\"\"\n",
    "    Classifies tracks based on geometric and temporal metrics.\n",
    "    \"\"\"\n",
    "    # Calculate movement efficiency (path per frame)\n",
    "    # This helps identify objects that were stationary (Static) at any point in the ROI\n",
    "    metrics['movement_efficiency'] = metrics['path_completeness'] / metrics['frames_count']\n",
    "\n",
    "    # --- Classification conditions ---\n",
    "\n",
    "    # 1. GHOST: Technical noise (very short tracks)\n",
    "    is_ghost = (metrics['frames_count'] < 10)\n",
    "\n",
    "    # 2. STATIC: Stationary object (at start, end, or in traffic jam)\n",
    "    # If there's too little movement per frame\n",
    "    is_static = (metrics['movement_efficiency'] < 0.0015) | \\\n",
    "                ((metrics['frames_count'] > 200) & (metrics['path_completeness'] < 0.3))\n",
    "\n",
    "    # 3. PERFECT: Ideal passage (stable width, full path, normal speed)\n",
    "    is_perfect = (\n",
    "        (metrics['path_completeness'] > 0.85) & \n",
    "        (metrics['w_cv'] < 0.30) & \n",
    "        (metrics['movement_efficiency'] >= 0.0015)\n",
    "    )\n",
    "\n",
    "    # 4. ENTRY/EXIT: Full passages where height changed regularly (ID 153, 238, etc.)\n",
    "    is_entry_exit = (\n",
    "        (metrics['path_completeness'] > 0.85) & \n",
    "        (metrics['w_cv'] < 0.30) & \n",
    "        (metrics['h_cv'] > 0.35)\n",
    "    )\n",
    "\n",
    "    # 5. FLICKERING: Unstable object (strong width jumps)\n",
    "    is_flickering = (metrics['w_cv'] > 0.45)\n",
    "\n",
    "    # 6. PARTIAL: Stable fragments (vehicles that appeared/disappeared mid-frame)\n",
    "    is_partial = (\n",
    "        (metrics['path_completeness'].between(0.3, 0.85)) & \n",
    "        (metrics['w_cv'] < 0.30)\n",
    "    )\n",
    "\n",
    "    # Priority order (from most important/simplest to general)\n",
    "    conditions = [\n",
    "        is_ghost,\n",
    "        is_static,\n",
    "        is_perfect,\n",
    "        is_entry_exit,\n",
    "        is_flickering,\n",
    "        is_partial\n",
    "    ]\n",
    "\n",
    "    choices = [\n",
    "        'Ghost', \n",
    "        'Static', \n",
    "        'Perfect', \n",
    "        'EntryExit', \n",
    "        'Flickering', \n",
    "        'Partial'\n",
    "    ]\n",
    "\n",
    "    # All others become candidates for merging (RelayCandidate)\n",
    "    metrics['category'] = np.select(conditions, choices, default='RelayCandidate')\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def categorize_ids(df):\n",
    "    \"\"\"\n",
    "    Aggregates raw data into metrics for each vehicle and classifies them.\n",
    "    \"\"\"\n",
    "    # Convert time and sort for calculation stability\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df = df.sort_values(['session_id', 'date_time', 'frame_id'])\n",
    "\n",
    "    # Group by session and ID\n",
    "    grouped = df.groupby(['session_id', 'vehicle_id'])\n",
    "    \n",
    "    # ROI height (according to your settings 460 - 170)\n",
    "    ROI_H = 290 \n",
    "    \n",
    "    # Data aggregation\n",
    "    metrics = grouped.agg(\n",
    "        y_start=('y', 'first'),\n",
    "        y_end=('y', 'last'),\n",
    "        w_mean=('width', 'mean'),\n",
    "        w_std=('width', 'std'),\n",
    "        h_mean=('heigth', 'mean'),\n",
    "        h_std=('heigth', 'std'),\n",
    "        frames_count=('frame_id', 'count'),\n",
    "        t_start=('date_time', 'min'),\n",
    "        t_end=('date_time', 'max'),\n",
    "        x_mean=('x', 'mean'),\n",
    "        x_std=('x', 'std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate path completeness (0.0 - 1.0)\n",
    "    metrics['path_completeness'] = (metrics['y_end'] - metrics['y_start']).abs() / ROI_H\n",
    "\n",
    "    # Calculate size stability (Coefficient of Variation)\n",
    "    # Use fillna(0) for single-frame objects\n",
    "    metrics['w_cv'] = (metrics['w_std'] / metrics['w_mean']).fillna(0)\n",
    "    metrics['h_cv'] = (metrics['h_std'] / metrics['h_mean']).fillna(0)\n",
    "\n",
    "    # Run classification\n",
    "    final_summary = classify_tracks(metrics)\n",
    "    \n",
    "    return final_summary\n",
    "\n",
    "final_summary = categorize_ids(session_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary.groupby('category').agg('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# 1. Parameters\n",
    "dims = ['path_completeness', 'frames_count', 'movement_efficiency', 'w_cv', 'h_cv']\n",
    "categories = final_summary['category'].unique()\n",
    "n = len(dims)\n",
    "\n",
    "# 2. Create subplot grid\n",
    "fig = make_subplots(\n",
    "    rows=n, cols=n, \n",
    "    shared_xaxes=False, shared_yaxes=False,\n",
    "    horizontal_spacing=0.03, vertical_spacing=0.03,\n",
    "    column_titles=dims, row_titles=dims\n",
    ")\n",
    "\n",
    "# Color palette (matches your previous plots)\n",
    "colors = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A']\n",
    "\n",
    "# 3. Fill the matrix\n",
    "for i, y_col in enumerate(dims):\n",
    "    for j, x_col in enumerate(dims):\n",
    "        for k, cat in enumerate(categories):\n",
    "            df_sub = final_summary[final_summary['category'] == cat]\n",
    "            \n",
    "            # If not enough data for KDE (less than 2 points), skip the curve\n",
    "            if len(df_sub) < 2: continue\n",
    "\n",
    "            if i == j: # DIAGONAL: Smooth KDE curves\n",
    "                # Calculate KDE\n",
    "                x_range = np.linspace(final_summary[x_col].min(), final_summary[x_col].max(), 100)\n",
    "                try:\n",
    "                    kde = gaussian_kde(df_sub[x_col])\n",
    "                    y_kde = kde(x_range)\n",
    "                    \n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=x_range, y=y_kde, \n",
    "                            name=cat, line=dict(color=colors[k], width=2),\n",
    "                            fill='tozeroy', opacity=0.3, # Fill under the curve\n",
    "                            showlegend=(i == 0 and j == 0),\n",
    "                            legendgroup=cat\n",
    "                        ),\n",
    "                        row=i+1, col=j+1\n",
    "                    )\n",
    "                except: pass # In case of zero variance\n",
    "\n",
    "            else: # OFF-DIAGONAL: Scatter plots\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=df_sub[x_col], y=df_sub[y_col],\n",
    "                        mode='markers', name=cat, marker_color=colors[k],\n",
    "                        opacity=0.5, marker_size=4,\n",
    "                        showlegend=False, legendgroup=cat,\n",
    "                        hovertext=df_sub['vehicle_id'].apply(lambda x: f\"ID: {x}\")\n",
    "                    ),\n",
    "                    row=i+1, col=j+1\n",
    "                )\n",
    "\n",
    "# 4. Configure fixed axes (per your request)\n",
    "for i, col in enumerate(dims):\n",
    "    margin = (final_summary[col].max() - final_summary[col].min()) * 0.05\n",
    "    r = [final_summary[col].min() - margin, final_summary[col].max() + margin]\n",
    "    \n",
    "    for k in range(1, n + 1):\n",
    "        fig.update_xaxes(range=r, row=k, col=i+1)\n",
    "        if i != k-1: # Don't touch Y axis for diagonal, as it has density scale\n",
    "            fig.update_yaxes(range=r, row=i+1, col=k)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Interactive matrix with distribution curves (KDE) on diagonal\",\n",
    "    width=1200, height=1100,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac013720",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_final_summary = final_summary[(final_summary['category'] == 'RelayCandidate')]\n",
    "filtered_final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f884c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_plot = filtered_final_summary['vehicle_id']\n",
    "plot_data = session_df[session_df['vehicle_id'].isin(ids_to_plot)]\n",
    "visualize_vehicle_trajectories(plot_data, session_id=0, max_vehicles=25, min_records=20, category='RelayCandidate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_merging_pairs(summary_df, time_gap_limit=1.5, space_gap_limit=40, size_sim_limit=0.2):\n",
    "    \"\"\"\n",
    "    summary_df: result of metrics calculation (final_summary)\n",
    "    time_gap_limit: max time gap (seconds)\n",
    "    space_gap_limit: max distance between points (pixels)\n",
    "    size_sim_limit: max width difference (relative, 0.2 = 20%)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Work only with Relay candidates\n",
    "    candidates = summary_df[(summary_df['category'] == 'RelayCandidate') | (summary_df['category'] == 'Static')].copy()\n",
    "    \n",
    "    # Sort by appearance time\n",
    "    candidates = candidates.sort_values('t_start')\n",
    "    \n",
    "    merges = []\n",
    "    used_ids = set()\n",
    "\n",
    "    # Convert to list of dictionaries for fast iteration\n",
    "    records = candidates.to_dict('records')\n",
    "\n",
    "    for i in range(len(records)):\n",
    "        id_a = records[i]\n",
    "        if id_a['vehicle_id'] in used_ids: continue\n",
    "\n",
    "        for j in range(i + 1, len(records)):\n",
    "            id_b = records[j]\n",
    "            if id_b['vehicle_id'] in used_ids: continue\n",
    "            \n",
    "            # 1. Session check (must be in the same session)\n",
    "            if id_a['session_id'] != id_b['session_id']: continue\n",
    "\n",
    "            # 2. Time gap (A ended, B started soon after)\n",
    "            gap_time = (id_b['t_start'] - id_a['t_end']).total_seconds()\n",
    "            \n",
    "            # We're looking for B that comes AFTER A, but not later than the limit\n",
    "            if 0 <= gap_time <= time_gap_limit:\n",
    "                \n",
    "                # 3. Spatial proximity (end of A to start of B)\n",
    "                # Use Y as it's the main axis of movement\n",
    "                dist_y = abs(id_b['y_start'] - id_a['y_end'])\n",
    "                dist_x = abs(id_b['x_mean'] - id_a['x_mean'])\n",
    "                \n",
    "                # 4. Size similarity (width shouldn't jump)\n",
    "                size_diff = abs(id_a['w_mean'] - id_b['w_mean']) / id_a['w_mean']\n",
    "\n",
    "                if dist_y < space_gap_limit and dist_x < 20 and size_diff < size_sim_limit:\n",
    "                    merges.append({\n",
    "                        'old_id': int(id_a['vehicle_id']),\n",
    "                        'new_id': int(id_b['vehicle_id']),\n",
    "                        'gap_sec': round(gap_time, 2),\n",
    "                        'y_dist': round(dist_y, 1),\n",
    "                        'size_diff_pct': round(size_diff * 100, 1)\n",
    "                    })\n",
    "                    # Mark IDs as used to avoid incorrect chain merging\n",
    "                    # (although chains of 3 IDs do happen too)\n",
    "                    used_ids.add(id_b['vehicle_id'])\n",
    "                    break \n",
    "\n",
    "    return pd.DataFrame(merges)\n",
    "\n",
    "# Function call\n",
    "merge_results = find_merging_pairs(final_summary)\n",
    "print(f\"Found pairs for merging: {len(merge_results)}\")\n",
    "print(merge_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa29075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2567fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ca181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['year'] = df['date_time'].dt.year\n",
    "# df['month'] = df['date_time'].dt.month\n",
    "# df['day'] = df['date_time'].dt.day\n",
    "# df['hour'] = df['date_time'].dt.hour\n",
    "# df['unique_vehicle_id'] = round(df['vehicle_id'] + df['year']/10000 + df['month']/1000000 + df['day']/100000000 + df['hour']/10000000000, 10)\n",
    "# df['unique_frame_id'] = round(df['vehicle_id'] + df['year']/10000 + df['month']/1000000 + df['day']/100000000 + df['hour']/10000000000, 10)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['size'] = df['width'] * df['heigth']\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d72220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df = df.groupby('unique_vehicle_id')[['size', 'y']].agg(['max', 'min']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df['way_size'] = min_max_df['y']['max'] - min_max_df['y']['min']\n",
    "# min_max_df.columns = ['size_max', 'size_min', 'y_max', 'y_min', 'way_size']\n",
    "# min_max_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df['full_way'] = min_max_df['way_size'] > 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add02eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df['day'] = min_max_df.index.map(lambda x: True if 6 <= int((x* 10000000000)%100) < 18 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad595500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
